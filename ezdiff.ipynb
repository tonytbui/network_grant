{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ezdiff import ezdiff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/Users/tonyb/Documents/Networking_Pilot/'\n",
    "raw_dir = project_dir + 'all_data/'\n",
    "explore_dir = project_dir + 'explore_n33/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and remove duplicated columns, mean and STD rows, and prefix from colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_df = pd.read_csv(explore_dir+'ezdiff/concat_separate_conditions_RTs_add0.5error_forACC=1.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv() automatically adds '.1' to duplicated columns. Remove here\n",
    "rt_df = rt_df.drop([i for i in rt_df.columns if '.1' in i],axis=1)\n",
    "rt_df = rt_df.iloc[2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove prefix from colnames for ease of indexing b/w 2 dataframes later\n",
    "rt_new_columns = []\n",
    "for i in range(len(rt_df.columns)):\n",
    "    rt_new_columns.append('_'.join(rt_df.columns[i].split('rt)_')[1:]))\n",
    "rt_df.columns = rt_new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.read_csv(explore_dir+'ezdiff/concat_separate_conditions_Accuracy_add0.5error_forACC=1.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = acc_df.drop([i for i in acc_df.columns if '.1' in i],axis=1)\n",
    "acc_df = acc_df.iloc[2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_new_columns = []\n",
    "for i in range(len(acc_df.columns)):\n",
    "    acc_new_columns.append('_'.join(acc_df.columns[i].split('acc_')[1:]))\n",
    "acc_df.columns = acc_new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wagermakers et al.'s (2007) EZ-Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ez_df = pd.DataFrame(columns=rt_new_columns)\n",
    "for i in rt_df.columns:\n",
    "    len_NaN_RTs = len(rt_df.loc[rt_df[i].isnull() , i])\n",
    "    len_NaN_ACCs = len(acc_df.loc[acc_df[i].isnull() , i])\n",
    "    ez_df.loc['NaN_RTs',i] = len_NaN_RTs\n",
    "    ez_df.loc['NaN_ACCs',i] = len_NaN_ACCs\n",
    "    #ezdiff() converts MRT to seconds and VRT to squared seconds\n",
    "    temp = ezdiff(rt_df.iloc[:33,rt_df.columns.get_loc(i)],acc_df.iloc[:33,acc_df.columns.get_loc(i)])\n",
    "    ez_df.loc['MRT',i] = temp[0] #mean of RTs (in seconds)\n",
    "    ez_df.loc['VRT',i] = temp[1] #variance of RTs (in seconds)\n",
    "    ez_df.loc['PC',i] = temp[2] #Percentage of correct responses\n",
    "    ez_df.loc['a',i] = temp[3] #Boundary separation a\n",
    "    ez_df.loc['v',i] = temp[4] #Driff rate v\n",
    "    ez_df.loc['t',i] = temp[5] #Nondecision time Ter (in seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ez_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This will write, altogether into one sheet, conditions/variables from all tasks with no repetition of those from dual tasks (i.e. 8 single tasks + combination 8 choose 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove SS:stop because stop-signal tasks use tracking mechanisms that keep stop-fail rate at 0.5\n",
    "#remove GNG:nogo because there are many NaN_RTs in nogo conditions (i.e., too few nongo fails)\n",
    "with pd.ExcelWriter(explore_dir+'ezdiff/ezdiff_add0.5error_forACC=1_removeSS-stop_removeGNG-nogo.xlsx', engine=\"openpyxl\") as writer:\n",
    "    ez_df[[i for i in ez_df.columns if ('SS:stop' not in i) and ('GNG:nogo' not in i)]].to_excel(writer, sheet_name='all_tasks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This will write each task cluster (1 single task, followed by all 7 related dual tasks) into a separate worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove SS:stop because stop-signal tasks use tracking mechanisms that keep stop-fail rate at 0.5\n",
    "#remove GNG:nogo because there are many NaN_RTs in nogo conditions (i.e., too few nongo fails)\n",
    "ez_df = ez_df[[i for i in ez_df.columns if ('SS:stop' not in i) and ('GNG:nogo' not in i)]]\n",
    "\n",
    "for task in ['CUE:','DF:','FLANKER:','GNG:','DELAY:','PREDICT:','SHAPE:','SS:']:\n",
    "    task_cols = [col for col in ez_df.columns if task in col]\n",
    "    if task == 'CUE:': \n",
    "        #cued_task_switching_single_task's columns are in format: TASK:..._&_CUE:..., \n",
    "        #unlike other single tasks, whose columns are in format, e.g.: DF:...\n",
    "        single_cols = [single for single in task_cols if len(single.split('&'))< 3]\n",
    "    else:\n",
    "        single_cols = [single for single in task_cols if '&' not in single]\n",
    "    dual_cols = [dual for dual in task_cols if dual not in single_cols]\n",
    "    \n",
    "    task_df = ez_df[single_cols+dual_cols]\n",
    "    if task == 'DELAY:':\n",
    "        task = 'NBACK:'\n",
    "    #write to separate sheets in same Excel workbook\n",
    "    with pd.ExcelWriter(explore_dir+'ezdiff/ezdiff_add0.5error_forACC=1_removeSS-stop_removeGNG-nogo.xlsx', engine=\"openpyxl\", mode='a') as writer:\n",
    "        task_df.to_excel(writer, sheet_name='%s' %task[:-1])\n",
    "    #write to separate .csv files\n",
    "    #task_df.to_csv('/Users/tonyb/Desktop/temp/%s.csv' %task[:-1],index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If wrote to separate .csv files, this is to check for completeness (e.g., same # of columns generated or not; single columns come first or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/tonyb/Documents/')\n",
    "from tb_utils.tb_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CUE; 27\n",
      "TASK:stay_&_CUE:stay\n",
      "TASK:switch_&_CUE:switch\n",
      "TASK:stay_&_CUE:stay_&_DF:con\n",
      "TASK:stay_&_CUE:stay_&_DF:neg\n",
      "\n",
      "DF; 27\n",
      "DF:con\n",
      "DF:neg\n",
      "TASK:stay_&_CUE:stay_&_DF:con\n",
      "TASK:stay_&_CUE:stay_&_DF:neg\n",
      "\n",
      "Flanker; 27\n",
      "FLANKER:congruent\n",
      "FLANKER:incongruent\n",
      "TASK:stay_&_CUE:stay_&_FLANKER:congruent\n",
      "TASK:stay_&_CUE:stay_&_FLANKER:incongruent\n",
      "\n",
      "GNG; 15\n",
      "GNG:go\n",
      "TASK:stay_&_CUE:stay_&_GNG:go\n",
      "TASK:switch_&_CUE:switch_&_GNG:go\n",
      "DF:con_&_GNG:go\n",
      "\n",
      "N-back; 27\n",
      "DELAY:1\n",
      "DELAY:2\n",
      "TASK:stay_&_CUE:stay_&_DELAY:1\n",
      "TASK:stay_&_CUE:stay_&_DELAY:2\n",
      "\n",
      "PREDICT; 27\n",
      "PREDICT:stay\n",
      "PREDICT:switch\n",
      "TASK:stay_&_CUE:stay_&_PREDICT:stay\n",
      "TASK:stay_&_CUE:stay_&_PREDICT:switch\n",
      "\n",
      "SHAPE; 27\n",
      "SHAPE:CONTROL\n",
      "SHAPE:DISTRACTOR\n",
      "TASK:stay_&_CUE:stay_&_SHAPE:CONTROL\n",
      "TASK:stay_&_CUE:stay_&_SHAPE:DISTRACTOR\n",
      "\n",
      "SS; 15\n",
      "SS:go\n",
      "TASK:stay_&_CUE:stay_&_SS:go\n",
      "TASK:switch_&_CUE:switch_&_SS:go\n",
      "DF:con_&_SS:go\n"
     ]
    }
   ],
   "source": [
    "for file in ordered_glob('/Users/tonyb/Desktop/temp/*'):\n",
    "    task = os.path.basename(file).split('.')[0]\n",
    "    df = pd.read_csv(file)\n",
    "    print('\\n%s; %s' %(task,len(df.columns)))\n",
    "    for i in df.columns[1:5]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
